{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c18d5-b5c6-4091-90b3-ff572073e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lore_sa import sklearn_classifier_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a2873-be41-4e88-b046-a4d6d0c0b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('german_credit.csv')\n",
    "\n",
    "# Define X and y\n",
    "X = df.drop(columns='default')\n",
    "y = df['default']\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), [1, 4, 7, 10, 12, 15, 17]),\n",
    "        ('cat', OrdinalEncoder(), [0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build model pipeline\n",
    "model = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "bbox = sklearn_classifier_bbox.sklearnBBox(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddff383-f5fd-4fcf-8f50-e4b182c52f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lore_sa.dataset import TabularDataset\n",
    "from lore_sa.neighgen import GeneticGenerator\n",
    "from lore_sa.encoder_decoder import ColumnTransformerEnc\n",
    "from lore_sa.lore import Lore\n",
    "from lore_sa.surrogate import DecisionTreeSurrogate\n",
    "from sklearn.preprocessing import FunctionTransformer  # For identity encoding\n",
    "\n",
    "# Load dataset\n",
    "dataset = TabularDataset.from_csv('german_credit.csv', class_name=\"default\")\n",
    "dataset.df.dropna(inplace=True)\n",
    "dataset.update_descriptor()\n",
    "\n",
    "enc = ColumnTransformerEnc(dataset.descriptor)\n",
    "enc.target_encoder = FunctionTransformer(func=lambda x: x, inverse_func=lambda x: x)\n",
    "\n",
    "generator = GeneticGenerator(bbox, dataset, enc)\n",
    "surrogate = DecisionTreeSurrogate()\n",
    "\n",
    "# Initialize Lore\n",
    "tabularLore = Lore(bbox, dataset, enc, generator, surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5c01d-727f-4a5c-9270-e8c06928e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_id = 7  # You can pick any row index\n",
    "# Drop the target column 'default' before passing to explain\n",
    "instance = dataset.df.drop(columns='default').iloc[instance_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf7869-7ce1-4c48-b86d-291ff4924347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explanation = tabularLore.explain(instance)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5bc421-1811-44b7-9523-b9924220b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_rule(explanation):\n",
    "    return {premise['attr'] for premise in explanation['rule']['premises']}\n",
    "\n",
    "# Example usage\n",
    "features_used = get_features_from_rule(explanation)\n",
    "print(\"Features used in the explanation (main rule):\", features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cef321-a64f-4bbe-a69d-5b0e14ec6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([instance])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c522c3e-1492-4738-902c-a08111bd6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Get predicted class\n",
    "predicted_class = model.predict([instance])\n",
    "print(predicted_class)\n",
    "\n",
    "# Step 1: Get predicted probabilities\n",
    "proba = model.predict_proba([instance])[0]  # Gives probabilities for each class\n",
    "print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3936ab-9e04-40f7-b3ba-0c2cbadb0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Get index of predicted class\n",
    "class_index = list(model.classes_).index(predicted_class)\n",
    "print(class_index)\n",
    "\n",
    "# Step 4: Get confidence score\n",
    "original_confidence_score = proba[class_index]\n",
    "print(original_confidence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f164cc2-30ad-464e-a7f4-ceb048ea4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Features to perturb\n",
    "features_to_perturb = features_used\n",
    "\n",
    "# Original instance\n",
    "instance1 = dataset.df.iloc[instance_id].copy()\n",
    "original_instance = instance1.drop(labels='default')\n",
    "\n",
    "# Predict original class\n",
    "original_pred_class = model.predict([original_instance])[0]\n",
    "print(f\"Original predicted class: {original_pred_class}\")\n",
    "\n",
    "def get_random_value_excluding(column, exclude_value):\n",
    "    col_data = dataset.df[column].dropna()\n",
    "\n",
    "    # Numerical feature\n",
    "    if pd.api.types.is_numeric_dtype(col_data):\n",
    "        # Calculate IQR\n",
    "        Q1 = col_data.quantile(0.25)\n",
    "        Q3 = col_data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define IQR range\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Filter values in IQR range (excluding the original value)\n",
    "        filtered_values = col_data[(col_data >= lower_bound) & \n",
    "                                   (col_data <= upper_bound) & \n",
    "                                   (col_data != exclude_value)]\n",
    "\n",
    "        if filtered_values.empty:\n",
    "            return exclude_value  # fallback\n",
    "\n",
    "        return np.random.choice(filtered_values)\n",
    "    \n",
    "    # Categorical feature\n",
    "    else:\n",
    "        unique_values = col_data.astype(str).unique()\n",
    "        filtered_values = [val for val in unique_values if val != str(exclude_value)]\n",
    "        \n",
    "        if not filtered_values:\n",
    "            return exclude_value  # fallback\n",
    "\n",
    "        return np.random.choice(filtered_values)\n",
    "\n",
    "# Lists for tracking\n",
    "confidence_scores = []\n",
    "class_changes = 0\n",
    "n_iterations = 100\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Perturb the instance\n",
    "    perturbed_instance = original_instance.copy()\n",
    "    for feature in features_to_perturb:\n",
    "        perturbed_instance[feature] = get_random_value_excluding(feature, original_instance[feature])\n",
    "    \n",
    "    perturbed_df = pd.DataFrame([perturbed_instance])\n",
    "\n",
    "    # Predict class and confidence\n",
    "    predicted_proba = model.predict_proba(perturbed_df)[0]\n",
    "    predicted_class = model.predict(perturbed_df)[0]\n",
    "    confidence = predicted_proba[predicted_class]\n",
    "\n",
    "    confidence_scores.append(confidence)\n",
    "\n",
    "    # Check and report class change\n",
    "    if predicted_class != original_pred_class:\n",
    "        class_changes += 1\n",
    "        print(f\"[{i+1}] Class changed to: {predicted_class} with confidence: {confidence:.4f}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nOut of {n_iterations} perturbations:\")\n",
    "print(f\"- Class changed {class_changes} times\")\n",
    "print(f\"- Mean confidence: {np.mean(confidence_scores):.4f}\")\n",
    "print(f\"Min: {np.min(confidence_scores):.4f}, Max: {np.max(confidence_scores):.4f}\")\n",
    "\n",
    "# Difference from original\n",
    "differences = [original_confidence_score - c for c in confidence_scores]\n",
    "print(f\"\\nAverage drop in confidence vs. original: {np.mean(differences):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934196e-098b-4ef3-a231-14d1309dd76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_rule(explanation):\n",
    "    return {premise['attr'] for premise in explanation['rule']['premises']}\n",
    "\n",
    "# Get features used in the explanation\n",
    "features_used = get_features_from_rule(explanation)\n",
    "\n",
    "# Get all feature names from the dataset (excluding target column 'default')\n",
    "all_features = dataset.df.drop(columns='default').columns\n",
    "\n",
    "# Get features not used in the explanation\n",
    "unused_features = [feature for feature in all_features if feature not in features_used]\n",
    "\n",
    "print(\"Features NOT used in the explanation:\", unused_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d225d-2be6-4713-a2fa-7391feb1f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Features to perturb\n",
    "features_to_perturb = unused_features\n",
    "\n",
    "# Original instance\n",
    "instance1 = dataset.df.iloc[instance_id].copy()\n",
    "original_instance = instance1.drop(labels='default')\n",
    "\n",
    "# Predict original class\n",
    "original_pred_class = model.predict([original_instance])[0]\n",
    "print(f\"Original predicted class: {original_pred_class}\")\n",
    "\n",
    "def get_random_value_excluding(column, exclude_value):\n",
    "    unique_values = dataset.df[column].dropna().unique()\n",
    "    filtered_values = [val for val in unique_values if val != exclude_value]\n",
    "    return np.random.choice(filtered_values)\n",
    "\n",
    "# Lists for tracking\n",
    "confidence_scores = []\n",
    "class_changes = 0\n",
    "n_iterations = 100\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Perturb the instance\n",
    "    perturbed_instance = original_instance.copy()\n",
    "    for feature in features_to_perturb:\n",
    "        perturbed_instance[feature] = get_random_value_excluding(feature, original_instance[feature])\n",
    "    \n",
    "    perturbed_df = pd.DataFrame([perturbed_instance])\n",
    "\n",
    "    # Predict class and confidence\n",
    "    predicted_proba = model.predict_proba(perturbed_df)[0]\n",
    "    predicted_class = model.predict(perturbed_df)[0]\n",
    "    confidence = predicted_proba[predicted_class]\n",
    "\n",
    "    confidence_scores.append(confidence)\n",
    "\n",
    "    # Check and report class change\n",
    "    if predicted_class != original_pred_class:\n",
    "        class_changes += 1\n",
    "        print(f\"[{i+1}] Class changed to: {predicted_class} with confidence: {confidence:.4f}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nOut of {n_iterations} perturbations:\")\n",
    "print(f\"- Class changed {class_changes} times\")\n",
    "print(f\"- Mean confidence: {np.mean(confidence_scores):.4f}\")\n",
    "print(f\"Min: {np.min(confidence_scores):.4f}, Max: {np.max(confidence_scores):.4f}\")\n",
    "\n",
    "# Difference from original\n",
    "differences = [original_confidence_score - c for c in confidence_scores]\n",
    "print(f\"\\nAverage drop in confidence vs. original: {np.mean(differences):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b0191-a49b-4ff0-8b42-0572117524f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Features to perturb\n",
    "features_to_perturb = unused_features\n",
    "\n",
    "# Original instance\n",
    "instance1 = dataset.df.iloc[instance_id].copy()\n",
    "original_instance = instance1.drop(labels='default')\n",
    "\n",
    "# Predict original class\n",
    "original_pred_class = model.predict([original_instance])[0]\n",
    "print(f\"Original predicted class: {original_pred_class}\")\n",
    "\n",
    "def get_random_value_excluding(column, exclude_value):\n",
    "    col_data = dataset.df[column].dropna()\n",
    "\n",
    "    # Numerical feature\n",
    "    if pd.api.types.is_numeric_dtype(col_data):\n",
    "        # Calculate IQR\n",
    "        Q1 = col_data.quantile(0.25)\n",
    "        Q3 = col_data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define IQR range\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Filter values in IQR range (excluding the original value)\n",
    "        filtered_values = col_data[(col_data >= lower_bound) & \n",
    "                                   (col_data <= upper_bound) & \n",
    "                                   (col_data != exclude_value)]\n",
    "\n",
    "        if filtered_values.empty:\n",
    "            return exclude_value  # fallback\n",
    "\n",
    "        return np.random.choice(filtered_values)\n",
    "    \n",
    "    # Categorical feature\n",
    "    else:\n",
    "        unique_values = col_data.astype(str).unique()\n",
    "        filtered_values = [val for val in unique_values if val != str(exclude_value)]\n",
    "        \n",
    "        if not filtered_values:\n",
    "            return exclude_value  # fallback\n",
    "\n",
    "        return np.random.choice(filtered_values)\n",
    "\n",
    "# Lists for tracking\n",
    "confidence_scores = []\n",
    "class_changes = 0\n",
    "n_iterations = 100\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Perturb the instance\n",
    "    perturbed_instance = original_instance.copy()\n",
    "    for feature in features_to_perturb:\n",
    "        perturbed_instance[feature] = get_random_value_excluding(feature, original_instance[feature])\n",
    "    \n",
    "    perturbed_df = pd.DataFrame([perturbed_instance])\n",
    "\n",
    "    # Predict class and confidence\n",
    "    predicted_proba = model.predict_proba(perturbed_df)[0]\n",
    "    predicted_class = model.predict(perturbed_df)[0]\n",
    "    confidence = predicted_proba[predicted_class]\n",
    "\n",
    "    confidence_scores.append(confidence)\n",
    "\n",
    "    # Check and report class change\n",
    "    if predicted_class != original_pred_class:\n",
    "        class_changes += 1\n",
    "        print(f\"[{i+1}] Class changed to: {predicted_class} with confidence: {confidence:.4f}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nOut of {n_iterations} perturbations:\")\n",
    "print(f\"- Class changed {class_changes} times\")\n",
    "print(f\"- Mean confidence: {np.mean(confidence_scores):.4f}\")\n",
    "print(f\"Min: {np.min(confidence_scores):.4f}, Max: {np.max(confidence_scores):.4f}\")\n",
    "\n",
    "# Difference from original\n",
    "differences = [original_confidence_score - c for c in confidence_scores]\n",
    "print(f\"\\nAverage drop in confidence vs. original: {np.mean(differences):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede378b-f2a8-4809-ba15-070358d534e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
